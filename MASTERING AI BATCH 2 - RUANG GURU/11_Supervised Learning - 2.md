# Supervised Learning - 2 (Webinar #11)

---

## ğŸ“š Overview Materi
Webinar ini membahas 3 topik utama:
1. **Matriks & Vektor**
2. **Linear Algebra**
3. **KNN (K-Nearest Neighbors)**

---

## ğŸ”¢ 1. MATRIKS & VEKTOR

### Jenis-Jenis Bilangan

#### 1.1 Skalar
Skalar = angka biasa
```
x = 6
```

#### 1.2 Vektor
Vektor = array satu dimensi
```
v = [1, 2, 3]
```

**Operasi Vektor:**

**âœ… Perkalian dengan Skalar (BISA)**
```
2 Ã— [1, 2, 3] = [2, 4, 6]
```
Semua elemen dikali 2!

**âŒ Penjumlahan Skalar + Vektor (TIDAK BISA)**
```
2 + [1, 2, 3] = âŒ ERROR!
```

**âœ… Penjumlahan Vektor + Vektor (BISA)**
Syarat: dimensi harus sama!
```
[1, 2, 3] + [4, 5, 6] = [5, 7, 9]
```
Dijumlahkan satu per satu!

**âœ… Dot Product Vektor**
```
[1, 2, 3] â€¢ [4, 5, 6] = ?
```
Cara hitung:
```
(1Ã—4) + (2Ã—5) + (3Ã—6)
= 4 + 10 + 18
= 32
```
**PENTING:** Hasilnya SKALAR (bukan vektor)!

#### 1.3 Matriks
Matriks = array dua dimensi

Contoh matriks 2Ã—3 (2 baris, 3 kolom):
```
[1  2  3]
[4  5  6]
```

**Cara baca ukuran:** **Baris Ã— Kolom** (row Ã— column)

**Hubungan dengan Vektor:**
Vektor = matriks berukuran nÃ—1
```
[1]
[2]  â†’ Matriks 3Ã—1
[3]
```

**Operasi Matriks:**

**âœ… Penjumlahan Matriks**
```
[1  2]   [5  6]   [6   8]
[3  4] + [7  8] = [10  12]
```
Tinggal tambahkan satu per satu!

**âœ… Dot Product Matriks**
Ini yang agak tricky! Pakai cara **"dua jari"**:
- Jari kiri: gerak ke kanan
- Jari kanan: gerak ke bawah

Contoh:
```
[1  2]   [5]
[3  4] â€¢ [6]
```

Cara hitung:
```
Baris 1: (1Ã—5) + (2Ã—6) = 5 + 12 = 17
Baris 2: (3Ã—5) + (4Ã—6) = 15 + 24 = 39

Hasil: [17]
       [39]
```

**SYARAT Dot Product:**
Kalau A berukuran **mÃ—n** dan B berukuran **nÃ—p**:
- Yang di tengah (n) **HARUS SAMA**
- Hasil akhir: **mÃ—p**

Contoh:
- (2Ã—3) â€¢ (3Ã—2) = âœ… BISA â†’ hasil 2Ã—2
- (2Ã—3) â€¢ (4Ã—2) = âŒ TIDAK BISA (3 â‰  4)

**PENTING:** Urutan penting!
```
A â€¢ B â‰  B â€¢ A
```

Tapi asosiatif (urutan operasi bebas):
```
(A â€¢ B) â€¢ C = A â€¢ (B â€¢ C)
```

### Operasi Khusus Matriks

#### Transpose
Tukar baris jadi kolom, kolom jadi baris
```
[1  2  3]áµ€   [1  4]
[4  5  6]  = [2  5]
             [3  6]
```

Yang semula nulis ke kanan â†’ jadi nulis ke bawah!

#### Identity Matrix (I)
Untuk **penjumlahan**: I = matriks nol
```
[0  0]
[0  0]
```

Untuk **dot product**: I = diagonal 1
```
[1  0  0]
[0  1  0]  â†’ ukuran 3Ã—3
[0  0  1]
```

Sifat:
```
A â€¢ I = A
```

#### Inverse Matrix (Aâ»Â¹)
Definisi:
```
A â€¢ Aâ»Â¹ = I
```

**Kegunaan:** Menyelesaikan persamaan linear!

---

## ğŸ“Š Aplikasi Matriks: Menyelesaikan Persamaan Linear

**Contoh Soal:**
```
2 apel + 1 jeruk = $5
3 apel + 4 jeruk = $10

Berapa harga 1 apel dan 1 jeruk?
```

**Solusi Tradisional:**
1. Substitusi
2. Eliminasi

**Solusi dengan Matriks:**

Tulis dalam bentuk matriks:
```
[2  1] [x]   [5]
[3  4] [y] = [10]
```

Atau: **A â€¢ X = B**

Untuk dapat X:
```
X = Aâ»Â¹ â€¢ B
```

**Langkah-langkah:**
1. Hitung Aâ»Â¹ (pakai NumPy)
```python
import numpy as np
A = np.array([[2, 1], [3, 4]])
A_inv = np.linalg.inv(A)
```

2. Kalikan Aâ»Â¹ dengan B
```python
B = np.array([5, 10])
X = A_inv.dot(B)
```

3. Done! X sekarang berisi nilai x dan y

**Kelebihan cara ini:**
- Bisa untuk sistem persamaan yang BANYAK (x, y, z, a, b, c, ...)
- Cepat kalau pakai komputer!

---

## ğŸ¯ 2. LINEAR ALGEBRA

### Visualisasi Vektor

Vektor punya **dua properti:**
1. **Arah** (direction)
2. **Panjang** (magnitude)

Contoh vektor [2, 1]:
```
     y
     â†‘
     1 â€¢ (2,1)
     |/
     |___â†’
   O   2   x
```
- Mulai dari origin (0,0)
- Gerak 2 ke kanan, 1 ke atas
- Vektor = panah dari O ke titik (2,1)

**PENTING:** Vektor yang sama bisa digambar di lokasi berbeda!
```
Vektor [2,1] bisa di mana saja
Selama arah & panjang sama = vektor yang sama
```

### Transformasi dengan Matriks

Kita bisa **merotasi**, **memperbesar**, atau **mengubah** vektor pakai matriks!

#### Contoh: Rotasi 90Â° (berlawanan jarum jam)

**Cara Tradisional (SMA):**
Hafal rumus rotasi... ğŸ˜µ

**Cara Praktis:**

Gunakan 2 vektor test:
1. [1, 0] â†’ kalau dirotasi 90Â° jadi [0, 1]
2. [0, 1] â†’ kalau dirotasi 90Â° jadi [-1, 0]

Cari matriks transformasi [a b; c d]:

Dari [1, 0] â†’ [0, 1]:
```
[a  b] [1]   [0]
[c  d] [0] = [1]

â†’ a = 0, c = 1
```

Dari [0, 1] â†’ [-1, 0]:
```
[a  b] [0]   [-1]
[c  d] [1] = [0]

â†’ b = -1, d = 0
```

**Matriks rotasi 90Â°:**
```
[0  -1]
[1   0]
```

Sekarang bisa rotasi vektor apapun!
```
[0  -1] [2]   [-1]
[1   0] [1] = [2]
```
Vektor [2, 1] jadi [-1, 2] âœ…

**Aplikasi Real:** CNN (Computer Vision)
- Filter untuk deteksi tepi
- Bottom edge detector
- Top edge detector
- Vertical/horizontal line detector
- Smoothing
- Semua pakai operasi matriks!

### Mengukur Panjang Vektor

#### 1. Euclidean Distance (Jarak Langsung)
Pakai **Pythagoras**!

Vektor [1, 1]:
```
Panjang = âˆš(1Â² + 1Â²) = âˆš2 â‰ˆ 1.41
```

Vektor [3, 4]:
```
Panjang = âˆš(3Â² + 4Â²) = âˆš(9 + 16) = âˆš25 = 5
```

#### 2. Manhattan Distance (Jarak Kota)
Jalan horizontal + vertikal (kayak mobil di kota)

Vektor [1, 1]:
```
Panjang = |1| + |1| = 2
```

**Kenapa disebut Manhattan?**
Karena jalanan di Manhattan, New York itu kotak-kotak kayak papan catur! Nggak bisa jalan diagonal, harus horizontal-vertikal.

```
Grid Manhattan:
â–¡â”€â–¡â”€â–¡â”€â–¡
â”‚ â”‚ â”‚ â”‚
â–¡â”€â–¡â”€â–¡â”€â–¡
â”‚ â”‚ â”‚ â”‚
â–¡â”€â–¡â”€â–¡â”€â–¡
```

---

## ğŸ¨ Aplikasi Real: Cosine Similarity (Preview NLP)

Kata bisa diubah jadi vektor!
```
"queen" â†’ [0.2, 0.8, 0.3, ...]
"king"  â†’ [0.3, 0.7, 0.4, ...]
"dog"   â†’ [0.9, 0.1, 0.2, ...]
```

**Cosine Similarity** = mengukur sudut antar vektor

**Sudut kecil** = kata mirip
- queen vs king â†’ sudut kecil âœ…
- queen vs dog â†’ sudut besar âŒ

**Aplikasi:**
- **Semantic Search** di Tokopedia/Shopee
  - Cari "handphone" â†’ muncul juga "HP", "smartphone", "gawai"
  - Tanpa perlu bikin dictionary manual!
  
- **Multilingual Search**
  - Cari pakai Bahasa Indonesia
  - Hasil bisa dari database Bahasa Inggris!

**Teknologi:** Vector Database (Pinecone, etc.)
- Menyimpan embedding (vektor) dari kata/kalimat
- Search berdasarkan semantic, bukan cuma keyword

---

## ğŸ¤– 3. K-NEAREST NEIGHBORS (KNN)

### Konsep Dasar

KNN = algoritma yang **super simple** tapi **powerful**!

**Prinsip:** "Teman sejati terlihat dari tetangganya" ğŸ˜ï¸

### Cara Kerja

**Contoh kasus:** Prediksi kanker vs non-kanker

**Data training:**
```
     y (umur)
     â†‘
     â€¢ (merah = kanker)
     â€¢â—‹
   â—‹ â€¢ â—‹ (biru = non-kanker)
     â—‹â€¢
     â€¢â—‹â€¢
     â””â”€â”€â”€â”€â†’ x (ukuran tumor)
```

**Ada data baru (?):**
```
     y
     â†‘
     â€¢
     â€¢â—‹
   â—‹ â€¢ ? â† Data baru, label apa?
     â—‹â€¢
     â€¢â—‹â€¢
     â””â”€â”€â”€â”€â†’ x
```

**Cara prediksi:**
1. Tentukan K (misalnya K=3)
2. Cari 3 tetangga terdekat dari (?)
3. Lihat warna mayoritas tetangga
4. (?) dapat label mayoritas!

```
3 tetangga terdekat: â€¢ â—‹ â€¢
Merah: 2, Biru: 1
â†’ Mayoritas MERAH
â†’ Prediksi: KANKER âœ…
```

### Langkah-Langkah KNN

1. **Split data** â†’ training set & test set
2. **Pilih K** (jumlah tetangga)
3. **Pilih distance metric** (Euclidean/Manhattan)
4. **Untuk setiap data baru:**
   - Hitung jarak ke semua data training
   - Ambil K tetangga terdekat
   - Vote mayoritas â†’ itu prediksi!

### Kode Python (Scikit-learn)

```python
from sklearn.neighbors import KNeighborsClassifier

# Buat model
knn = KNeighborsClassifier(n_neighbors=11, metric='euclidean')

# Training
knn.fit(X_train, y_train)

# Prediksi
y_pred = knn.predict(X_test)

# Evaluasi
from sklearn.metrics import confusion_matrix, f1_score
print(confusion_matrix(y_test, y_pred))
print(f1_score(y_test, y_pred))
```

### Mencari K Optimal

**Cara 1: Heuristic**
```
K = âˆšn
(n = jumlah data training)
```
Contoh: 100 data â†’ coba K=10 dulu

**Cara 2: Brute Force**
Coba K dari 1 sampai 20, pilih yang akurasi terbaik!

```python
# Coba berbagai K
for k in range(1, 20):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    score = knn.score(X_test, y_test)
    print(f'K={k}, Accuracy={score}')
```

Plot hasilnya, pilih K dengan akurasi tertinggi + standard deviation rendah!

### Feature Selection (Penting!)

**Memilih feature yang tepat = kunci sukses KNN!**

**Contoh Kanker:**
- âœ… Ukuran tumor
- âœ… Umur pasien
- âŒ Nama pasien (gak relevan!)
- âŒ Warna baju (gak relevan!)

**Contoh Pilpres (analogi):**
Prediksi pilihan presiden seseorang:
- âœ… Umur
- âœ… Pendidikan terakhir
- âœ… Domisili (tetangga geografis biasanya pilihan sama!)
- âŒ Tinggi badan
- âŒ Warna favorit

**Cara memilih feature:**
1. **Tanya expert** (dokter untuk kanker, politisi untuk pilpres)
2. **Feature engineering** (dari materi sebelumnya)
3. **Trial & error** (coba-coba, lihat mana yang performanya bagus)

### Kelebihan KNN

âœ… **Super simple** - algoritma paling gampang dipahami!  
âœ… **No training needed** - langsung pakai, gak perlu training lama  
âœ… **Fleksibel** - bisa untuk klasifikasi & regresi  
âœ… **Bisa bikin decision boundary kompleks** (lingkaran, zigzag, dll)

### Kelemahan KNN

âŒ **Curse of Dimensionality**
- Kalau feature terlalu banyak (10, 100, 1000 dimensi)
- Data jadi "sparse" (jarang, jauh-jauh)
- Konsep "tetangga dekat" jadi gak bermakna

âŒ **Sensitif terhadap feature selection**
- Kalau pilih feature salah â†’ hasil salah!

âŒ **Lambat untuk data besar**
- Harus hitung jarak ke SEMUA data training
- Kalau 10,000 data â†’ 10,000 kali perhitungan jarak!

---

## ğŸ“Œ Notasi Matematika (Bonus)

### Sigma (Î£) - Penjumlahan
```
  5
  Î£  (2i + 1)
 i=2

= (2Ã—2+1) + (2Ã—3+1) + (2Ã—4+1) + (2Ã—5+1)
= 5 + 7 + 9 + 11
= 32
```

### Pi (Î ) - Perkalian
```
  4
  Î   i
 i=2

= 2 Ã— 3 Ã— 4
= 24
```

---

## ğŸ¯ Rangkuman

**Matriks & Vektor:**
- Matriks = representasi data
- Operasi matriks = fundamental untuk ML
- GPU = super cepat untuk operasi matriks!

**Linear Algebra:**
- Vektor = punya arah & panjang
- Transformasi matriks = rotasi, scaling, dll
- Aplikasi: CNN, computer vision

**KNN:**
- Algoritma super simple tapi efektif
- Prinsip: tetangga terdekat menentukan label
- Pilih K & feature dengan bijak!
- Evaluasi: confusion matrix, F1-score

---

## ğŸ’¡ Tips Belajar

1. **Matrix operations akan terus muncul** di materi selanjutnya (Deep Learning, NLP)
2. **Praktek coding** lebih penting daripada hafal rumus
3. **Pakai Copilot/ChatGPT** untuk belajar syntax Python/Pandas
4. **Version control is a must** - commit & push ke GitHub!
5. **Jangan lupa deadline project!** 23:59 malam ini!

---

**Next Week:** Classification & Decision Trees ğŸŒ²

*"Bahasa Inggris adalah bahasa pemrograman masa depan"* - dengan GPTs! ğŸš€
